---
layout: post
date: '2017-10-11 23:36 +0100'
author: Kyle McCann
published: false
categories: Honors Project
meta: Honours Project Strathclyde Glasgow Software Engineering
---
## Project Overview##


In recent years there has been an emergence of the use of voice for searching. More commonly known examples of this are Apple’s Siri and Amazon’s Alexa.

The project is suggested by Lucidworks, who contribute code to products such as Lucene and Solr which are open source search platforms. The primary aim of this project is to Implement a search interface that integrates Speech To Text APIs and demonstrates a voice driven search application with basic features of Siri/Google Now on top of Lucidworks search platform. The main motivation behind this is to enhance the user experience and allow users to retrieve search results quickly in natural language.

The project should be done as open source (hosted on Github) with an Apache Software Foundation-friendly license (https://www.apache.org/legal/3party.html, i.e no GPL, AGPL or LGPL or similarly viral licenses.) 

In addition to the development of a voice search interface on top of Lucidworks Fusion, there is a research element to the project. I will evaluate different voice search API’s that are openly available. In addition to this I will carry out comparative research between traditional text search and voice search. Also since when people speak they tend to be more verbose the finished product will need to extract a good query from the speech, methods to do this will need to be researched.

### Blog location
http://www.kyle.im 

### Achievable Objectives
**Basic - Prototype / Proof of Concept**  
Research and evaluation of different speech to text API’s.
Understanding of Fusion and how it can be used to create a search platform.


**Intermediate - Fully useable search interface**  
Implement a working voice search interface which works with Lucidworks Fusion.
Comparison between traditional text based search and voice based search.
Gain an understanding of Natural Language Processing.
Investigate best method of extracting a good query from verbose speech.
                

**Advanced - Increasing accuracy**  
There are various more advanced idea which could potentially be developed including:
Investigate methods of dealing with background noise
Clarification of results
Addition of Voice commands

### Survey of Related Work
There are a variety of different players in the voice to text search space. I will look at how the larger of these companies implement their own API’s in there search products. I will then make a comparison on these with a detailed breakdown of the benefits of each API. The open-source nature of the project will also be a factor in picking an API for the final product.

***Google***  
Google has implemented voice search into a variety of products. Including but not limited to: Google Search, Maps, Google Home.

***Apple***  
Apple's main voice search offering is Siri which is in effect a personal assistant on your Apple devices. It allows you to carry out task such as setting appointments, sending emails, calling a friend and information retrieval from the web. However Apple does not currently offer an API which allows you to use its technology on web based projects.

***IBM***  
IBM offers the technology of Watson speech to text technology. This is available via a free API to developers. 

***Amazon***  
Amazon's main use of speech to text is it’s use of it technology within the Amazon Echo or Alexa. This is a small household device which allows you to carry out actions or control other smart home enabled devices which are within your home. Amazon allows the use of their API which enables developers to implement there alexa technology in any connected device.

### Methodology
Most popular and established methodologies were made with larger projects with teams of multiple people, therefore I will tailor these methodologies to suit an independently developed system.

**Agile Development Methods**  
Sprints - These are short focussed goals that take place over the course of one or two weeks and result in a new working version of the product. The first of these will be a prototype system that can be used to test the different API’s available for speech to text.

**Prototype Process Model**  
The prototype process model is a systems development method In which a prototype is initially developed this is then evaluated and used as a basis for the final implementation. 

**Project Evaluation**  
The project specification will initially be formed from the project proposal. It will then be developed after discussion with Lucidworks and potential users of the product.

Once the system has been developed to a useable state I will form a usability study with a small group of users, the main aim of the study will be to record the accuracy of the returned results and how usable they thought the system was. I will use the results of this to evaluate the system. Furthermore it may also be possible to have some evaluation done by Lucidworks employees.
### Project Plan
Project Scope and Outline Plan - Monday 16th October
Research available speech to text API’s - November 
Design and Implement prototype - December  
Project Poster due - Friday 12th January
Project Report and Project code submission - Monday 26th March 
### Marking Scheme
Experimentation-based with Significant Software Development Project
Student Performance - 10% 
Project Product - total: 25% 
Software - 20%
Documentation - 5% 
Project Process - total: 30% 
Background study, requirements analysis, and design - 25% 
Testing - 5% 
Project Results and Evaluation - 25% 
Report Presentation - 10%
